\listfiles
% \RequirePackage{rotating}
% \documentclass[format=manuscript]{acmart}
\documentclass[format=manuscript, screen,review=true]{acmart}
%\documentclass[format=acmsmall, screen]{acmart}

% bibliography
% using biblatex isn't very smart because journals are pretty picky. Instead use the default natbib package
% \usepackage[backend=biber,style=trad-abbrv,citecounter=true]{biblatex}
% \addbibresource{References.bib}
%
% \renewcommand{\finentrypunct}{%
  % \addperiod\space
  % (Cited \arabic{citecounter}~time\ifnumequal{\value{citecounter}}{1}{}{s})%
% }

%\setcitestyle{super,sort&compress}
% \citestyle{acmauthoryear}
\usepackage{booktabs} % For formal tables
\usepackage[ruled]{algorithm2e} % For algorithms
\usepackage{subcaption}
\usepackage[printwatermark]{xwatermark}
\usepackage{xcolor}
\usepackage{graphicx}
\usepackage{tikz}
\usepackage{nameref}

% \newsavebox\mybox
% \savebox\mybox{\tikz[color=red,opacity=0.3]\node{1st Round Revisions};}
% \newwatermark*[
  % allpages,
  % angle=45,
  % scale=6,
  % xpos=-35,
  % ypos=30
% ]{\usebox\mybox}

% Metadata Information
\acmJournal{CSUR}
\acmVolume{01}
\acmNumber{01}
\acmArticle{01}
\acmYear{2018}
\acmMonth{01}

%\acmBadgeL[http://ctuning.org/ae/ppopp2016.html]{ae-logo}
% \acmBadgeR[http://ctuning.org/ae/ppopp2016.html]{ae-logo}

% Copyright
% \setcopyright{acmcopyright}
%\setcopyright{acmlicensed}
\setcopyright{rightsretained}
%\setcopyright{usgov}
%\setcopyright{usgovmixed}
%\setcopyright{cagov}
%\setcopyright{cagovmixed}

% DOI
\acmDOI{0000001.0000001}

% some useful shortcut commands
\newcommand{\Pl}{\textbf{Pl}}
\newcommand{\R}{\textbf{R}}
\newcommand{\nisarcomm}[1]{{\color{red} (NRA: #1)}}
\newcommand{\brettcomm}[1]{{\color{blue} (BWI: \textbf{#1})}}
\newcommand{\edit}[1]{{\color{blue} #1}}
\newcommand{\hlr}[1]{{\color{red} #1}}

\received{November 2017}
%% 35 pages with references!!!
% Document starts
\begin{document}
% Title portion
\title{``Dave\ldots I can assure you \ldots that it's going to be all right \ldots''} 
 \titlenote{HAL 9000, \textit{2001 A Space Odyssey}, full quote: ``Just what do you think you're doing, Dave? Dave, I really think I'm entitled to an answer to that question. I know everything hasn't been quite right with me, but I can assure you now, very confidently, that it's going to be all right again.''
 }
 \subtitle{A definition, case for, and survey of algorithmic assurances in human-autonomy trust relationships}
 % \subtitlenote{Subtitle note}
\author{Brett W. Israelsen}
    \orcid{0000-0003-1602-1685}
    \email{brett.israelsen@colorado.edu}
    % \affiliation{%
        % \institution{University of Colorado, Boulder}
        % \department{Department of Computer Science}
        % \city{Boulder}
        % \state{CO}
        % \country{USA}
    % }
    % \affiliation{%
        % \institution{RECUV}
    % }
    % \affiliation{%
        % \institution{C-UAS}
    % }
\author{Nisar R. Ahmed}
\authornote{The corresponding author}
    \email{nisar.ahmed@colorado.edu}
    \affiliation{%
        \institution{University of Colorado Boulder}
        % \department{Ann and H.J. Smead Aerospace Engineering Sciences}
        \city{Boulder}
        \state{CO}
        \country{USA}
    }
    \affiliation{%
        \institution{\href{https://cohrint.info/}{Cooperative Human-Robot Intelligence  Laboratory (COHRINT)}}
    }
    \affiliation{%
        \institution{\href{http://www.colorado.edu/recuv/}{Research and Engineering Center for Unmanned Vehicles (RECUV)}}
    }
    %CUAS affiliation is not needed/considered
    %\affiliation{%
    %    \institution{\href{https://c-uas.org/}{Center for Unmanned Aircraft Systems (C-UAS)}}
    %}

\begin{abstract}
    Humans have devised and designed methods by which they can asses whether the systems they have created can be trusted to work as desired, typically in an ad hoc, informal, fashion. This same desire applies to the more nascent, and advanced, technologies like artificially intelligent, autonomous systems; those who design, use, and are otherwise affect by this technology want to know that it will perform correctly, and understand the reasons behind its actions, and know how to use it appropriately. In short: they want to be able to \emph{trust} such systems. Herein a suvery of \emph{algorithmic assurances} that allow users to calibrate their trust, and use them more appropriately. To this end algorithmic assurances are first formally defined, and classified, from the perspective of human-autonomy trust relationships. A survey is performed using research from related communities such as interpretable, comprehensible, transparent, and explainable machine learning, as well as human-computer interaction, human-robot interaction, e-commerce, and others. The survey contains practical indications of how practitioners can design and apply assurances. Recommendations and directions for future work are also presented.
    \brettcomm{review this at the end, is it OK to use `artificially intelligent agent' here? I have been using more common (less accurate) words, to avoid specialized language in the abstract}
    %
    % With the advent of advanced, artificially intelligent, autonomous systems, those who design, use and are otherwise affected by this technology want to know that it will perform correctly, and understand why it does what it does, and how to use it appropriately.
    %
    %
    % That is, they want to be able to \emph{trust} such systems. This work provides a survey of \emph{algorithmic assurances} that allow users to calibrate their trust. Trust between humans and autonomy is reviewed, and the implications for the design of assurances are highlighted \nisarcomm{--todo: revise...this makes the goal of the paper unclear.} A survey of existing research related to algorithmic assurances is presented. Much of the surveyed research originates from fields such as interpretable, comprehensible, transparent, and explainable machine learning, as well as human-computer interaction, human-robot interaction, and e-commerce. Several key ideas are extracted from this work in order to refine the definition of assurances. The design of assurances is found to be highly dependent not only on the capabilities of the autonomous system, but on the characteristics of the human user, and the appropriate trust-related behaviors. Several directions for future research are identified and discussed. \nisarcomm{need to polish this up later...feels like a lot of words that describes details, but that aren't getting at the real core arguments of the paper...}
\end{abstract}

\begin{CCSXML}
<ccs2012>
<concept>
<concept_id>10003120</concept_id>
<concept_desc>Human-centered computing</concept_desc>
<concept_significance>500</concept_significance>
</concept>
<concept>
<concept_id>10010147.10010178</concept_id>
<concept_desc>Computing methodologies~Artificial intelligence</concept_desc>
<concept_significance>500</concept_significance>
</concept>
<concept>
<concept_id>10010147.10010257</concept_id>
<concept_desc>Computing methodologies~Machine learning</concept_desc>
<concept_significance>500</concept_significance>
</concept>
<concept>
<concept_id>10010147.10010341.10010342</concept_id>
<concept_desc>Computing methodologies~Model development and analysis</concept_desc>
<concept_significance>500</concept_significance>
</concept>
<concept>
<concept_id>10010405</concept_id>
<concept_desc>Applied computing</concept_desc>
<concept_significance>500</concept_significance>
</concept>
<concept>
<concept_id>10002978.10003029</concept_id>
<concept_desc>Security and privacy~Human and societal aspects of security and privacy</concept_desc>
<concept_significance>300</concept_significance>
</concept>
</ccs2012>
\end{CCSXML}

% \ccsdesc[500]{Human-centered computing}
% \ccsdesc[500]{Computing methodologies~Artificial intelligence}
% \ccsdesc[500]{Computing methodologies~Machine learning}
% \ccsdesc[500]{Computing methodologies~Model development and analysis}
% \ccsdesc[500]{Applied computing}
% \ccsdesc[300]{Security and privacy~Human and societal aspects of security and privacy}

% We no longer use \terms command
% \terms{Algorithms, Assurances, Trust}

\keywords{human-computer trust, interpretable machine learning, explainable artificial intelligence}

\thanks{This work was funded by a research gift from Northrop-Grumman Aerospace Systems and by the Center for Unmanned Aircraft Systems (C-UAS), a National Science Foundation Industry/University Cooperative Research Center (I/UCRC) under NSF Award No. CNS-1650468 along with significant contributions from C-UAS industry members.}

\maketitle

%%Please keep section headers in this part of the document for easier identification and separability and editing, need to avoid spaghetti code as much as possible.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}\label{sec:introduction}
\input{intro.tex}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Motivation and Background} \label{sec:background}
\input{background.tex}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Survey of Algorithmic Assurances} \label{sec:synthesis}
\input{survey.tex}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Future Work} \label{sec:future_work}
\input{future_work.tex}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusions}\label{sec:conclusions}
\input{conclusions.tex}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\bibliographystyle{ACM-Reference-Format}
\bibliography{References}
\end{document}
