\listfiles
% \RequirePackage{rotating}
% \documentclass[format=manuscript]{acmart}
\documentclass[format=manuscript, screen,review=true]{acmart}
%\documentclass[format=acmsmall, screen]{acmart}

% bibliography
% using biblatex isn't very smart because journals are pretty picky. Instead use the default natbib package
% \usepackage[backend=biber,style=trad-abbrv,citecounter=true]{biblatex}
% \addbibresource{References.bib}
%
% \renewcommand{\finentrypunct}{%
  % \addperiod\space
  % (Cited \arabic{citecounter}~time\ifnumequal{\value{citecounter}}{1}{}{s})%
% }

%\setcitestyle{super,sort&compress}
% \citestyle{acmauthoryear}
\usepackage{booktabs} % For formal tables
\usepackage[ruled]{algorithm2e} % For algorithms
\usepackage{subcaption}
\usepackage[printwatermark]{xwatermark}
\usepackage{xcolor}
\usepackage{graphicx}
\usepackage{tikz}
\usepackage{nameref}

% \newsavebox\mybox
% \savebox\mybox{\tikz[color=red,opacity=0.3]\node{1st Round Revisions};}
% \newwatermark*[
  % allpages,
  % angle=45,
  % scale=6,
  % xpos=-35,
  % ypos=30
% ]{\usebox\mybox}

% Metadata Information
\acmJournal{CSUR}
\acmVolume{01}
\acmNumber{01}
\acmArticle{01}
\acmYear{2018}
\acmMonth{01}

%\acmBadgeL[http://ctuning.org/ae/ppopp2016.html]{ae-logo}
% \acmBadgeR[http://ctuning.org/ae/ppopp2016.html]{ae-logo}

% Copyright
% \setcopyright{acmcopyright}
%\setcopyright{acmlicensed}
\setcopyright{rightsretained}
%\setcopyright{usgov}
%\setcopyright{usgovmixed}
%\setcopyright{cagov}
%\setcopyright{cagovmixed}

% DOI
\acmDOI{0000001.0000001}

% some useful shortcut commands
\newcommand{\Pl}{\textbf{Pl}}
\newcommand{\R}{\textbf{R}}
\newcommand{\nisarcomm}[1]{{\color{red} (NRA: #1)}}
\newcommand{\brettcomm}[1]{{\color{blue} (BWI: \textbf{#1})}}
\newcommand{\edit}[1]{{\color{blue} #1}}
\newcommand{\hlr}[1]{{\color{red} #1}}

\received{November 2017}
%% 35 pages with references!!!
% Document starts
\begin{document}
% Title portion
\title{``Dave\ldots I can assure you \ldots that it's going to be all right \ldots''} 
 \titlenote{HAL 9000, \textit{2001 A Space Odyssey}, full quote: ``Just what do you think you're doing, Dave? Dave, I really think I'm entitled to an answer to that question. I know everything hasn't been quite right with me, but I can assure you now, very confidently, that it's going to be all right again.''
 }
 \subtitle{A definition, case for, and survey of algorithmic assurances in human-autonomy trust relationships}
 % \subtitlenote{Subtitle note}
\author{Brett W. Israelsen}
    \orcid{0000-0003-1602-1685}
    \email{brett.israelsen@colorado.edu}
    % \affiliation{%
        % \institution{University of Colorado, Boulder}
        % \department{Department of Computer Science}
        % \city{Boulder}
        % \state{CO}
        % \country{USA}
    % }
    % \affiliation{%
        % \institution{RECUV}
    % }
    % \affiliation{%
        % \institution{C-UAS}
    % }
\author{Nisar R. Ahmed}
\authornote{The corresponding author}
    \email{nisar.ahmed@colorado.edu}
    \affiliation{%
        \institution{University of Colorado Boulder}
        % \department{Ann and H.J. Smead Aerospace Engineering Sciences}
        \city{Boulder}
        \state{CO}
        \country{USA}
    }
    \affiliation{%
        \institution{\href{https://cohrint.info/}{Cooperative Human-Robot Intelligence  Laboratory (COHRINT)}}
    }
    \affiliation{%
        \institution{\href{http://www.colorado.edu/recuv/}{Research and Engineering Center for Unmanned Vehicles (RECUV)}}
    }
    %CUAS affiliation is not needed/considered
    %\affiliation{%
    %    \institution{\href{https://c-uas.org/}{Center for Unmanned Aircraft Systems (C-UAS)}}
    %}

\begin{abstract}
    Those who design, use, and are otherwise affected by advanced, technologies like artificially intelligent, autonomous systems want to know that these systems will perform correctly, understand the reasons behind their actions, and know how to use them appropriately. 
    In short: they want to be able to \emph{trust} such systems. Consequently, designers have devised various kinds of assurances for assessing trust.  
    Typically, however, these assessments are ad hoc, and have not been formally related to each other or to formal trust models.  This paper presents a survey of \emph{algorithmic assurances} that allow users to calibrate their trust in autonomous artificially intelligent agents and use such autonomous agents more appropriately. To this end algorithmic assurances are first formally defined, and classified, from the perspective of formally modeled trust relationships. The survey is then performed using research from related communities such as machine learning, human-computer interaction, human-robot interaction, e-commerce, and others. The literature for different classes of assurances are identified with seven different levels of integration for artificially intelligent agents; these classes are useful for practitioners and system designers. Recommendations and directions for future work are also presented.
\end{abstract}

\begin{CCSXML}
<ccs2012>
<concept>
<concept_id>10003120</concept_id>
<concept_desc>Human-centered computing</concept_desc>
<concept_significance>500</concept_significance>
</concept>
<concept>
<concept_id>10010147.10010178</concept_id>
<concept_desc>Computing methodologies~Artificial intelligence</concept_desc>
<concept_significance>500</concept_significance>
</concept>
<concept>
<concept_id>10010147.10010257</concept_id>
<concept_desc>Computing methodologies~Machine learning</concept_desc>
<concept_significance>500</concept_significance>
</concept>
<concept>
<concept_id>10010147.10010341.10010342</concept_id>
<concept_desc>Computing methodologies~Model development and analysis</concept_desc>
<concept_significance>500</concept_significance>
</concept>
<concept>
<concept_id>10010405</concept_id>
<concept_desc>Applied computing</concept_desc>
<concept_significance>500</concept_significance>
</concept>
<concept>
<concept_id>10002978.10003029</concept_id>
<concept_desc>Security and privacy~Human and societal aspects of security and privacy</concept_desc>
<concept_significance>300</concept_significance>
</concept>
</ccs2012>
\end{CCSXML}

% \ccsdesc[500]{Human-centered computing}
% \ccsdesc[500]{Computing methodologies~Artificial intelligence}
% \ccsdesc[500]{Computing methodologies~Machine learning}
% \ccsdesc[500]{Computing methodologies~Model development and analysis}
% \ccsdesc[500]{Applied computing}
% \ccsdesc[300]{Security and privacy~Human and societal aspects of security and privacy}

% We no longer use \terms command
% \terms{Algorithms, Assurances, Trust}

\keywords{human-computer trust, interpretable machine learning, explainable artificial intelligence}

\thanks{This work was funded by a research gift from Northrop-Grumman Aerospace Systems and by the Center for Unmanned Aircraft Systems (C-UAS), a National Science Foundation Industry/University Cooperative Research Center (I/UCRC) under NSF Award No. CNS-1650468 along with significant contributions from C-UAS industry members.}

\maketitle

%%Please keep section headers in this part of the document for easier identification and separability and editing, need to avoid spaghetti code as much as possible.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}\label{sec:introduction}
\input{intro.tex}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Motivation and Background} \label{sec:background}
\input{background.tex}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Survey of Algorithmic Assurances} \label{sec:synthesis}
\input{survey.tex}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Future Work} \label{sec:future_work}
\input{future_work.tex}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusions}\label{sec:conclusions}
\input{conclusions.tex}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\bibliographystyle{ACM-Reference-Format}
\bibliography{References}
\end{document}
