\listfiles
% \RequirePackage{rotating}
% \documentclass[format=manuscript]{acmart}
\documentclass[format=manuscript, screen,review=true]{acmart}
%\documentclass[format=acmsmall, screen]{acmart}

% bibliography
% using biblatex isn't very smart because journals are pretty picky. Instead use the default natbib package
% \usepackage[backend=biber,style=trad-abbrv,citecounter=true]{biblatex}
% \addbibresource{References.bib}
%
% \renewcommand{\finentrypunct}{%
  % \addperiod\space
  % (Cited \arabic{citecounter}~time\ifnumequal{\value{citecounter}}{1}{}{s})%
% }

%\setcitestyle{super,sort&compress}
% \citestyle{acmauthoryear}
\usepackage{booktabs} % For formal tables
\usepackage[ruled]{algorithm2e} % For algorithms
\usepackage{subcaption}
\usepackage[printwatermark]{xwatermark}
\usepackage{xcolor}
\usepackage{graphicx}
\usepackage{tikz}
\usepackage{nameref}

% \newsavebox\mybox
% \savebox\mybox{\tikz[color=red,opacity=0.3]\node{1st Round Revisions};}
% \newwatermark*[
  % allpages,
  % angle=45,
  % scale=6,
  % xpos=-35,
  % ypos=30
% ]{\usebox\mybox}

% Metadata Information
\acmJournal{CSUR}
\acmVolume{01}
\acmNumber{01}
\acmArticle{01}
\acmYear{2018}
\acmMonth{01}

%\acmBadgeL[http://ctuning.org/ae/ppopp2016.html]{ae-logo}
% \acmBadgeR[http://ctuning.org/ae/ppopp2016.html]{ae-logo}

% Copyright
% \setcopyright{acmcopyright}
\setcopyright{acmlicensed}
% \setcopyright{rightsretained}
%\setcopyright{usgov}
%\setcopyright{usgovmixed}
%\setcopyright{cagov}
%\setcopyright{cagovmixed}
\input{ccs_classification.tex}

% DOI
\acmDOI{0000001.0000001}

% some useful shortcut commands
\newcommand{\Pl}{\textbf{Pl}}
\newcommand{\R}{\textbf{R}}
\newcommand{\nisarcomm}[1]{{\color{red} (NRA: #1)}}
\newcommand{\brettcomm}[1]{{\color{blue} (BWI: \textbf{#1})}}
\newcommand{\edit}[1]{{\color{blue} #1}}
\newcommand{\hlr}[1]{{\color{red} #1}}

\received{November 2017}
%% 35 pages with references!!!
% Document starts
\begin{document}
% Title portion
\title{``Dave\ldots I can assure you \ldots that it's going to be all right \ldots''} 
\titlenote{HAL 9000, \textit{2001 A Space Odyssey}, full quote: ``Just what do you think you're doing, Dave? Dave, I really think I'm entitled to an answer to that question. I know everything hasn't been quite right with me, but I can assure you now, very confidently, that it's going to be all right again.''
 }
\subtitle{A definition, case for, and survey of algorithmic assurances in human-autonomy trust relationships}
% \subtitlenote{Subtitle note}
\author{Brett W. Israelsen}
\authornote{Corresponding author}
    \orcid{0000-0003-1602-1685}
    \email{brett.israelsen@colorado.edu}
\author{Nisar R. Ahmed}
    \email{nisar.ahmed@colorado.edu}
    \affiliation{%
        \institution{University of Colorado Boulder}
        % \department{Ann and H.J. Smead Aerospace Engineering Sciences}
        \city{Boulder}
        \state{CO}
        \country{USA}
    }
    \affiliation{%
        \institution{%\href{https://cohrint.info/}
        {Cooperative Human-Robot Intelligence  Laboratory (COHRINT)}}
    }
    \affiliation{%
        \institution{%\href{http://www.colorado.edu/recuv/}
        {Research and Engineering Center for Unmanned Vehicles (RECUV)}}
    }

\begin{abstract}
    People who design, use, and are affected by autonomous artificially intelligent agents want to be able to \emph{trust} such agents -- that is, to know that these agents will perform correctly, to understand the reasoning behind their actions, and to know how to use them appropriately. 
    Many techniques have been devised to assess and influence human trust in artificially intelligent agents. However, these approaches are typically ad hoc, and have not been formally related to each other or to formal trust models. This paper presents a survey of \emph{algorithmic assurances}, i.e. programmed components of agent operation that are expressly designed to calibrate user trust in artificially intelligent agents. 
    Algorithmic assurances are first formally defined and classified from the perspective of formally modeled human-artificially intelligent agent trust relationships. Building on these definitions, a synthesis of research across communities such as machine learning, human-computer interaction, robotics, e-commerce, and others reveals that assurance algorithms naturally fall along a spectrum in terms of their impact on an agent's core functionality, with seven notable classes ranging from integral assurances (which impact an agent's core functionality) to supplemental assurances (which have no direct effect on agent performance). Common approaches within each of these classes are identified and discussed; benefits and drawbacks of different approaches are also investigated. %%This spectrum and set of classifications can be directly useful to designers of advanced artificially intelligent agents, who are concerned about trust and appropriate use. %%Remaining questions and opportunities for future research are also presented.
\end{abstract}

\keywords{human-computer trust, interpretable machine learning, explainable artificial intelligence, transparency, accountability, fairness, algorithmic assurances}

\thanks{The authors acknowledge the helpful feedback of Michael Mozer and Eric Frew, as well as that of the reviewers. This work was funded by a research gift from Northrop-Grumman Aerospace Systems and by the Center for Unmanned Aircraft Systems (C-UAS), a National Science Foundation Industry/University Cooperative Research Center (I/UCRC) under NSF Award No. CNS-1650468 along with significant contributions from C-UAS industry members.}

\maketitle

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}\label{sec:introduction}
\input{intro.tex}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Motivation and Background} \label{sec:background}
\input{background.tex}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Survey of Algorithmic Assurances} \label{sec:synthesis}
\input{survey.tex}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Future Work} \label{sec:future_work}
\input{future_work.tex}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\vspace{-0.1 in}

\section{Conclusions}\label{sec:conclusions}
\input{conclusions.tex}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\bibliographystyle{ACM-Reference-Format}
\bibliography{References}
\end{document}
