The formal design of algorithmic assurances is still an emerging field. Consequently, there are many opportunities for further research along different lines. This section outlines some possible promising directions for future work.

\vspace{-0.15 in}

\subsection{Properties of Assurances} \label{sec:assurance_props_future}
 Figure~\ref{fig:refined_trust} gives some hints about how designers might be able to fully characterize the properties of AIA assurances. In this survey we investigate, in some detail, `Level of Integration'. However all of the other grayed-out boxes in Figure~\ref{fig:refined_trust} have open questions that should still be investigated. 

\input{ass_st.tex}

\input{ass_cc.tex}

\input{ass_ei.tex}

\input{ass_tt.tex}

\subsection{Trust and Distrust}
The treatment of assurances in this survey is based, in part, on a model of interpersonal trust. For completeness it will be important to further investigate \textit{distrust}, as reviewed and discussed by \citet{Lewicki1998-ox}, and formalized in \citet{McKnight2001-gz}. Low trust is not the same as distrust, and low distrust is not the same as trust. \citet{McKnight2001-gz} suggest that `the emotional intensity of distrust distinguishes it from trust', and they explain that distrust comes from emotions like wariness, caution, and fear -- whereas trust stems from emotions like hope, safety, and confidence. Trust and distrust are orthogonal elements that define a person's TRB towards a trustee. Since distrust was not considered here, it is not clear to what extent the human-AIA trust model remains effective in the presence of user wariness, caution, or fear. Questions for future work include: to what extent can behaviors driven by distrust be isolated from those originating from trust? How can those behaviors be detected to begin with? And in what circumstances is the extra effort necessary? 

\subsection{Human Limitations}
Dealing with human users requires consideration of their cognitive limitations. For instance cognitive biases known as `framing effects' (reacting to the same choice in different ways depending on how it is presented) will be important to consider for designing usable AIAs that must make decisions under uncertainty ~\cite{Freedy2007-sg,Riley1996-qm}. The existence of framing effects are not surprising to those familiar with cognitive science, but they will likely be unanticipated phenomena to many AIA system designers. Other related cognitive biases and limitations such as `recency effects' (being biased in making choices based on recent experience), `focusing effects' (being biased in choice selection based on a single aspect of a correlated event), or `normalcy biases' (failure to consider situations which have never occurred before) are also important to consider. 

Besides cognitive biases, humans are also limited in their ability to understand certain kinds of information. Communities that investigate how probabilistic and statistical explanations can be presented to humans will have many insights that are relevant for AIA designers and assurance design \cite{Rouse1986-dz,Wallace2001-fm,Kuhn1997-qc,Lomas2012-ie,Swartout1983-ko}. But it is not immediately clear what methods are most appropriate for application in assurance design, or how they might be applied. For instance, can the AIA detect when cognitive limitations are effecting TRBs? What other user limitations need to be characterized? 

\input{perception_mediums.tex}
\input{obs_effects.tex}
