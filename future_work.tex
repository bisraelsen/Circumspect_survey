This field is nascent, and there are many opportunities for further research along different lines. This section outlines some possible directions for future work that are promising.

\subsection{Properties of Assurances} \label{sec:assurance_props_future}
Probably the most straight forward approach could be to draw some guidance from Figure~\ref{fig:refined_trust}, which shows how to classify an assurance. In this survey we investigate, in some detail, `Level of Integration'. However all of the other grayed-out boxes in that figure have open questions that can still be investigated. 

\input{ass_st.tex}

\input{ass_cc.tex}

\input{ass_ei.tex}

\input{ass_tt.tex}

\subsection{Trust vs. Distrust}
The treatment of assurances in this survey is based, in part, on a model of interpersonal trust. For completeness it will be important to further investigate \textit{distrust}, as reviewed and discussed by \citet{Lewicki1998-ox}, and formalized in \citet{McKnight2001-gz}. Low trust is not the same as distrust, and low distrust is not the same as trust. \citet{McKnight2001-gz} suggest that `the emotional intensity of distrust distinguishes it from trust', and they explain that distrust comes from emotions like: wariness, caution, and fear. Whereas, trust stems from emotions like: hope, safety, and confidence. Trust and distrust are orthogonal elements that define a person's TRB towards a trustee. Distrust was not considered here. It is not clear to what extent the human-AIA trust model remains effective in the presence of user wariness, caution, or fear. To what extent can behaviors driven by distrust be isolated from those originating from trust? How can those behaviors be detected to begin with? In what circumstances is the extra effort necessary? This topic needs to be investigated further.

\subsection{Human Limitations}
Dealing with human users implies addressing their limitations as well. Evidence of `framing effects' influencing operator behavior has been observed~\cite{Freedy2007-sg,Riley1996-qm}. While, this isn't surprising to those familiar with cognitive science, it will likely be surprising to many who are trying to implement assurances. Other cognitive biases and limitations such as `recency effects' (being biased based on recent experience), `focusing effects' (being biased based on a single aspect of an event), or `normalcy biases' (refusal to consider situations which have never occurred before) are also important to consider. 

Besides cognitive biases, humans are also limited in their ability to understand certain kinds of information. Communities that investigate how probabilistic and statistical explanations can be presented to humans will be useful in addressing this question \cite{Rouse1986-dz,Wallace2001-fm,Kuhn1997-qc,Lomas2012-ie,Swartout1983-ko}. It is not immediately clear what methods are most appropriate for application in assurance design, or how they might be applied. Can the AIA detect when cognitive limitations are effecting TRBs? What other limitations of relationships with humans and AIAs need to be characterized? Surely there are equally important limitations identified in psychology, sociology, economics, and others.

\input{perception_mediums.tex}
\input{obs_effects.tex}
