\subsection{Quadrant IV.}
Need to add different categories here. should be something like:
\subsubsection{Validation and Verification} \cite{Da_Veiga2012-gh} (constrained GP model), \cite{Da_Silva2016-qb}, \cite{Nishi2016-zq}, \cite{Hadfield-Menell2016-ws}, \cite{Weng_Wong2014-tj}, \cite{Conner2007-uw}, 
\subsubsection{Active Learning} \cite{Paul2011-vr}, \cite{Holub2008-pe}, \cite{Joshi2009-ws}, \cite{Kapoor2010-cy}, \cite{Triebel2013-ow}, \cite{MacKay1992-sp}
\subsubsection{Representation learning and Feature Selection} \cite{Bengio2013-uv}, \cite{Guyon2003-fj}, \cite{Haury2011-zi}, \cite{Mikolov2013-lt}(word2vec, I want to say something about how things are ranked by similarity, and this gives some notion of how a word is represented, i.e. interpretable encoding)
\subsubsection{Risk averse Agents} \cite{Curran2016-ij},  \cite{Lipton2016-dq}
\subsubsection{Safety and Learning under nonstationarity} \cite{Sugiyama2013-ci}, \cite{Garcia2015-rs},\cite{Quinonero-Candela2009-fj}
\subsubsection{Probabilistic Classification}
Introspection stuff -- \cite{Grimmett2013-gj}, \cite{Triebel2013-ku}, \cite{Triebel2016-kj}, \cite{Berczi2015-rd}, \cite{Grimmett2016-yc}, \cite{Dequaire2016-kh}
\subsubsection{Empirical Performance Prediction} \cite{Hutter2006-ak}, \cite{Leyton-Brown2009-yr}
\subsubsection{Theory Guided Data Science} \cite{Faghmous2014-og}
\subsubsection{Understanding ML methods} \cite{Bakry2015-td}, \cite{Konolige1985-vx} (introspection theory, provides capabilities to generate assurances),  
\subsubsection{More robust methods} \cite{Bashivan2015-fc},  \cite{Tellex2012-hn}
\subsubsection{Model checking} \cite{Titman2008-ct}, \cite{Laskey1995-jp} (sensitivity analysis), \cite{Sinharay2006-yc} (model diagnostics), \cite{Titman2012-zw} (HMM goodness of fit), \cite{MacKay_Altman2004-fl} (GOF for HMMs), \cite{Dannemann2008-ch}, \cite{Titman2010-qx}, \cite{Johnson2004-mv}, \cite{Yuan2012-tb}, \cite{Spiegelhalter2002-ia}
\subsubsection{Representation of Uncertainty} \cite{Laskey2015-gz}, \cite{Costa2012-fa}

    While a fairly high-level treatment, \citet{Amodei2016-xi} are concerned with `AI safety', which is in essence how to make sure that there is no ``unintended and harmful behavior that [emerges] from machine learning systems''. Given the definition, much of the paper discusses concepts that are critical to AIA assurances. Among the more directly applicable topics in the scope of this paper are: safe exploration (how to learn in a safe manner), and robustness to distributional shift (a difference between training data and test data). They also discuss designing objective functions that are more appropriate. These areas are critical 

\subsubsection{Not sure} , \cite{Gutfreund2016-xe} (constructs automatic arguments, perhaps similar to counter-planning?), \cite{Charif2013-vo} (agents cooperate based on abilities to accomplish goal)
