\section{Methodology} \label{sec:methodology}
    In this survey, I attempt to look at research of those who are formally and informally addressing the idea of human-AIA trust. In particular, I focus on a ideas that might be applicable to the trust relationship between a single human user (User), and a single autonomous vehicle. While theoretically a two-way trust model could be considered, I will only be considering a one-way trust relationship, that is that the autonomy has perfect trust towards a user.

    It should be noted that it is almost impossible to perform a comprehensive survey of all assurances due to the broad nature of assurances in general. One could rightly argue that metrics like gain and phase margins are assurances for control engineers, as are training and test accuracy for machine learning practioncioners. However, it is my opinion that the somewhat narrow view of the surveyed literature does not significantly hinder the definition or classification of assurances.

    In order to find applicable research I first looked at papers that formally addressed trust and tried to create models of it; this with the aim of trying to understand how it might be influenced. Secondly, I looked at some historical research regarding trust between humans and some form of non-human entity. This mainly lead to e-commerce literature, automation literature, and human-robot interactions. Third, I investigated work regarding `interpretable', `comprehensible', `transparent', `explainable', \ldots and other types of learning and modeling methods. Finally, I searched for research disciplines that are investigating methods that would be useful as assurances, but of which trust is not the main focus.

    With this information, I try to make an informed definition and classification of assurances based off of empirical information of methods that are currently in use or being investigated. In doing so I was able to identify several areas that are open for further research. 
