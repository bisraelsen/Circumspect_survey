\section{Methodology} \label{sec:methodology}
    \edit{This survey examines} research of those who are formally and informally addressing the idea of human-AIA trust. In particular, \edit{attention is devoted to} ideas that are applicable to the trust relationship between a single human user (User) and a single autonomous vehicle (AIA). While theoretically a two-way trust model could be considered (i.e. in which the trust the AIA has in the user is also considered), \edit{attention is restricted here to a one-way trust relationship that considers only how user trust evolves in response to assurances from the AIA}. 
    %that is that the autonomy has perfect trust towards a user -- NRA: not necessary to actually bring this up or make this assumption; basically it's not relevant to the scope of what you are surveying.

    It should be noted that it is almost impossible to perform a fully comprehensive survey of all \edit{AIA} assurances, \edit{due to the broad spectrum of possible assurances and AIAs in general}. One could rightly argue that \edit{control engineers} treat metrics like gain and phase margins \edit{as assurances for automatic feedback control systems, in much the same way that  machine learning practitioners treat training and test accuracy as assurances for learning algorithms} -- and hence concepts related to robustness, stability, etc. for feedback control systems ought also be included in this survey.  
%However, it is my opinion that the somewhat narrow view of the surveyed literature here does not significantly hinder definition or classification of assurances. 
\nisarcomm{I would edit the last sentence (commented out now) to basically say something to the effect that: (i) you are focusing on intelligent systems/AIA's specifically, and not `automatic'/dumb machinery [feedback control systems like your thermostat or cruise control or your toilet tank], because these are a newer and thus not so well understood beast (i.e. distinguish `human-automation trust' from `human-autonomy trust'); and (ii)
 that the fundamental insights and principles into the question of designing assurances for addressing the question of `is this thing working and trustable, or not?' can translate over to other non-AIA domains as well.}

\nisarcomm{edit/rephrase to get rid of first person voice, i.e. no `I did xxxx...' -- }    In order to find applicable research, I first looked at papers that formally addressed trust and tried to create models of it; this with the aim of trying to understand how it might be influenced. Secondly, I looked at some historical research regarding trust between humans and some form of non-human entity. This mainly lead to e-commerce literature, automation literature, and human-robot interactions. Third, I investigated work regarding `interpretable', `comprehensible', `transparent', `explainable', \ldots and other types of learning and modeling methods. Finally, I searched for research disciplines that are investigating methods that would be useful as assurances, but of which trust is not the main focus.

    With this information, I try to make an informed definition and classification of assurances based off of empirical information of methods that are currently in use or being investigated. In doing so I was able to identify several areas that are open for further research. 
