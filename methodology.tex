\subsection{Methodology} \label{sec:methodology}
    This survey examines formal and informal investigations of human-AIA trust. While theoretically a two-way trust model could be considered (i.e. in which the AIA also has trust in the user), attention is restricted here to a one-way trust relationship that considers only how user trust (and TRBs) evolves in response to assurances from the AIA. 

    It should be noted that it is practically impossible to perform a fully comprehensive survey of all AIA assurances, due to the broad spectrum of possible assurances, and AIAs in general. As an example, one could rightly argue that control engineers treat metrics like gain and phase margins as assurances for automatic feedback control systems, in much the same way that machine learning practitioners treat training and test accuracy as assurances for learning algorithms -- and hence concepts related to robustness, stability, etc. for feedback control systems ought also be included in this survey. While assurances can, in theory, be applied in both the most simple `automatic' systems (like a thermostat), this survey will focus on assurances in more advanced AIAs that make decisions under uncertainty. However, the admittedly narrow scope of this survey does not impede the development of fundamental insights and principles in designing assurances.

    Initially, in order to find applicable research, papers that formally addressed trust and tried to create models of it were investigated, with the aim of trying to understand how trust might be influenced. Secondly, literature was researched regarding trust between humans and some form of machine entity, leading to fields like e-commerce, automation, and human-robot interaction. Third, work regarding `interpretable', `comprehensible', `transparent', `explainable', and other similar types of learning and modeling methods were examined. Finally, with that literature as a background, research disciplines investigating computational methods that would be useful as assurances, but in which trust itself is not the main focus, were considered. This information was then used to construct an informed definition and classification of assurances based on methods that are currently in use, or being investigated.
    
    The insights from all of these papers are synthesized in Figure~\ref{fig:refined_assurances}, and discussed in more detail in the remainder of this section.
