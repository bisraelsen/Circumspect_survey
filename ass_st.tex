\subsubsection{Source-Target Classification}
    It is convenient to refer to assurances by way of their source and target. More specifically their source AIA behavior (see Figure \ref{fig:AIcapabilities}) and their user trust target component (see figure \ref{fig:Asurane_classes}. Intuitively, there may be a set of different algorithms that are useful for making assurances that convey information about planning to the competence dimension of the user's trust. It is easier to refer to these assurances in terms of their source and target. So, for this example that class of algorithms would be the `planning-competence' class.

    The source AIA capability for an assurance might be most easily thought of by the algorithm it has to operate on. If the assurance operates on, or comes from, a planning algorithm then it would be considered a `planning' source. If the algorithm operated on data for learning patterns, the it would be considered a `learning' source.

    The trust dimensions shown in Figure \ref{fig:Assurance_classes} are the possible targets for assurances. The categories mirror those of the trust model proposed by \citet{McKnight2001-fa}, but with the emphasis on what an AIA has the ability to most readily influence (and consequently where most research is found). The boxes with the beveled corner identify and define the different classes of assurances. All classes are included here for completeness and generality. Although, while it is hypothetically possible for an AIA to influence a persons general `Trusting stance' given enough time\footnote{One might imagine an AIA that specifically speaks to the human about the benefits or drawbacks about trusting even though there might not be evidence to do so, similar to the role a counselor might play}, the gray boxes are not considered further in this survey, as practically no direct research exists in the realm of human-AIA relationships.
    
    Not only is the source-target notation useful shorthand for communicating about the purpose of the assurance, but it is useful in classifying the range of assurance algorithms that exist. There may also be a class of algorithms that span multiple source-target capabilities. For example there may be a kind of algorithm that can give a `learning-competence' assurance, as well as a `planning-competence' assurance. This is especially true since many of the AIA capabilities can overlap. Also, the effects of assurances cannot be guaranteed to affect only one trust dimension (see section \ref{sec:imprecise}).
