\section{Survey Sections} \label{sec:survey}
Now that AIA, trust, TRBs, and assurances have been defined we are ready to begin the survey of assurances. Early in reading the related literature it became clear that there were two main groups: 1) those researchers who have formally addressed the topic of trust between humans and AIAs of some form, and 2) a much larger body of those who have informally considered trust in their work. Here we consider formal treatment of trust to include those who acknowledge a human trust model and who perform experiments that attempt to measure the effect of assurances on trust. Informal treatment of trust includes those who only reference a nebulous idea of trust, and who do not actually perform experiments to verify that proposed assurances actually do affect trust. 

There are two other  groups: 1) those who focus on explicitly designed assurances, or those assurances intentionally created by designers with the intent of affecting a user's trust, and 2) those who focus on implicit assurances, or those assurances that exist without the intention of affecting the trust of user's.

Much of the research that formally considers trust has focused on implicit assurances. This is likely due to the focus on analyzing the effect of autonomous systems on trust and not on designing systems for trust. However, as seen by a large spike in interest in `interpretable', and `explainable' AIAs in government, academic, and public circles, there is a large need for designed assurances.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.8\textwidth]{Figures/Trust_vs_Assurance_Intention.pdf}
    \caption{Figure depicting how many papers that consider trust formally/informally consider intentional/unintentional assurances, \textbf{need to put actual data here, if it is a useful figure, for now the data is approximate from my memory}}
    \label{fig:trust_assurance_intention}
\end{figure}

The remainder of this document will focus on surveying the assurance research in the formal/informal, explicit/implicit plane. Figure \ref{fig:trust_assurance_intention} shows the number of papers considered in this survey that lay in each quadrant of that plane. The quadrants are defined as:

\begin{itemize}
    \item \hyperref[sec:q1]{Quadrant I.} (implicit assurances, formal trust treatment) -- Use human experiments, consider a trust model, assurances are implicit (i.e. those who care about trust, but aren't designing assurance algorithms)
    \item \hyperref[sec:q2]{Quadrant II.} (explicit assurances, formal trust treatment) -- Use human experiments, consider a trust model, assurances are explicit (i.e. those who formally acknowledge trust from an AIA, and design assurances to affect it)
    \item \hyperref[sec:q3]{Quadrant III.} (explicit assurances, informal trust treatment) -- No human experiments, reference trust (or interpretability, etc..), proposed assurances are explicit (i.e. those who know that ``trust'' is important, but really just present their opinion about an algorithm that might be an assurance)
    \item \hyperref[sec:q4]{Quadrant IV.} (implicit assurances, informal trust treatment) -- don't reference trust, designed properties of AIA for better performance, typically reference some of the trust components such as predictability, and competence, but only in the context of the designer being happy. (i.e. those whose work is relevant for assurances, but they don't know it)
\end{itemize}

It is clear that much of the research that is relevant has occurred in the `informal trust treatment' half of the plane. The aim, in order to satisfy the need for increased trust in AIAs, is to create more research in Quadrant II. This would mean that assurances have been formally and explicitly designed to affect user's trust. One key observation, is that there is plenty of opportunity to `move' research from Quadrants I., III., and IV. to Quadrant II. In essence this would be taking proposed methods and putting them to the test using a formal understanding of trust and appropriately designed experiments.

\input{q1.tex}
\input{q2.tex}
\input{q3.tex}
\input{q4.tex}
