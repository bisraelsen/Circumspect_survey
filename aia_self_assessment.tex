\subsection{AIA Self-Assessment} \label{sec:aia_self_assessment}

\subsubsection{Common Approaches:}
\paragraph{Quantify Uncertainty} \label{sec:QU}
talk about these \citet{Wu2012-qi, Chen2018-xq, Choi2017-th, Kahn2017-vy, Peterson2017-dd, Kendall2017-ry, Zhang2014-he, Churchill2015-ei, Paul2011-vr, Grimmett2013-gj, Triebel2013-ku, Triebel2013-ow, Triebel2016-kj, Berczi2015-rd, Grimmett2016-yc, Dequaire2016-kh, Gurau2016-hs, Kuter2015-qh, Aitken2016-cv, MacKay1992-sp, Zagorecki2015-qy, Hutchins2015-if, Laskey1991-mf, Kaipa2015-hy, Habbema1976-xd}

\paragraph{Reduce Complexity} \label{sec:reduce_complexity}
talk about these: \citet{Liu2017-xw, Strumbelj2018-ou, Pynadath2018-ck, Abdollahi2018-uw, Robnik-Sikonja2018-jz, Browne2018-me, Huang2017-lk, Wang2018-br, Hayes2017-nt, Huang2017-zt, Olah2018-rp, Kuhn1997-qc, Rouse1986-dz, Swartout1983-ko, Wang2016-id, Kaniarasu2013-ho, Wallace2001-fm, Aitken2016-cv, Lacave2002-cu, Ribeiro2016-uc}

Other assurances for machine learning algorithms are inspired by the well-known trade-off between accuracy and interpretability, whereby improving the accuracy of a learner generally reduces its interpretability. \citet{Ruping2006-xj} asks how classification results and the accuracy-interpretability trade-off can be made more transparent to those who design and use classifiers, by combining simpler global models with more complex local models that are built around learning results (\citet{Otte2013-oo} and \citet{Ribeiro2016-uc} implement similar ideas as well). 

\subsubsection{Grounding Example:}
In the case of the `VIP Escort' problem (described in Section~\ref{sec:mot_example}), value alignment might be used as an assurance in the following way:

We make the following assumptions

\begin{itemize}
    \item The UGV has just begun an attempt to escape the road-network
    \item 
    \item 
\end{itemize}

\paragraph{\textbf{Discussion of Example:}} 
