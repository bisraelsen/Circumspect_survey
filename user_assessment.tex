\subsection{User Assessment} \label{sec:user_assessment}
talk about these: \citet{Yu2018-qw, Wickens1999-la, Riley1996-qm, Muir1996-gt, Desai2012-rc}
\brettcomm{this is communicating data (unprocessed), rely on human to do processing (as opposed to vis and DR). human limitations on cognition.}
\subsubsection{Common Approaches:}

\paragraph{stuff:}
One of the simplest approaches to helping users understand AIAs is to display the raw data being used, and rely on the user's own processing power to draw conclusions. In most real applications, however, there are too many individual variables for a human to attend to. Beyond that, users may have to be highly trained to interpret the results. In such situations, dimensionality reduction (DR) and visualization tools can be used to help make a model or data easier to understand. \citet{Venna2007-yj} discusses DR for ML and reviews many linear and non-linear projection methods. \citet{Vellido2012-nm} also discusses the importance of DR for making ML models interpretable. As one example, \citet{Chipman2005-om} applied this idea by constraining principle component analysis (PCA) in an attempt to make the resulting linear combinations of variables be more interpretable (more homogeneous, or more sparse).


\subsubsection{Grounding Example:}
In the case of the `VIP Escort' problem (described in Section~\ref{sec:mot_example}), value alignment might be used as an assurance in the following way:

We make the following assumptions

\begin{itemize}
    \item The UGV has just begun an attempt to escape the road-network
    \item 
    \item 
\end{itemize}

\paragraph{\textbf{Discussion of Example:}} 
