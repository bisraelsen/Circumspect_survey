\subsubsection{Explicit and Implicit Assurances}
Human's will always form some kind of trust relationship to an AIA, regardless of the presence of designed assurances. How then can a user inform their trust? They do so by using \emph{implicit}, undesigned, assurances. These can be thought of as assurances that are side-effects of other design decisions not meant to affect a user's trust.

Why is it important to consider implicit assurances? There is always a danger that users can attend to the `wrong' assurances, i.e. AIA features that are not meant to be interpreted as assurances but are nevertheless easily perceived (possibly moreso than intended explicit assurances). It is possible for implicit assurances to supersede explicit ones. For example a designer may make a planning-predictability assurance, however it could be rendered ineffective by an implicit assurance given by the appearance, or smell, or color of the AIA (think of marketing research here).

Future researchers might ask questions like: How can we know whether an explicit assurance is effective? And, are there implicit assurances that have a significant effect on user's trust and introducing a trust bias?

It is also worth considering, in more detail, what implications the existence of implicit and explicit assurances means practically for AIA system designers when it comes to considering and implementing assurances. 
Since it is unrealistic for designers to take all possible kinds assurances into account, they will need to focus their efforts on how to identify and focus on only the most important ones. 
The foremost consideration is that an analysis of the interaction between the human and user needs to be made in order to identify the critical assurances for a given scenario. 
For example, in the road network problem, an analysis might find that the most critical assurances are about the competence of the UGV's planner. 
In this case the designer must take time to design an explicit assurance that is directed at the user's perception of the AIA's competence -- let's call this a `planning-competence' assurance. 
One difficulty arises from this approach is that there doesn't seem to be a way to determine what other implicit assurances might drown out explicit assurances. 
Continuing the example, the system designer may come up with a well thought out planning-competence assurance, but failed to consider the effect of how the UGV appears -- it may be old, have loose panels, and rust holes. Generally, designers overlook implicit assurances (i.e. do not consider them explicitly in design) because they assume that they will have no effect (i.e. why does it matter if there are rust-holes if the UGV works?). This can stem from ignorance of human-AIA trust dynamics, or failure to identify which assurances are most important to users.

    While it might be desirable, it is generally unreasonable and practically inefficient to attempt a study of \emph{every possible} assurance from an AIA to a user and then select the most important. Perhaps one way a designer might try to identify which assurances are important is to perform user studies, to obtain feedback about which characteristics of the AIA most affected user trust. An approach like this would help determine if explicit assurances are being picked up, and if there are implicit assurances that are overly influential or that overwhelm explicitly designed assurances. With such feedback, designers would have a realistic idea about whether their explicitly designed assurances are having the desired effect on user TRBs. We use the UGV road-network problem to illustrate: after designing an explicit assurance, the supervisor-UGV team could work together in a training mission. Afterwards, the supervisor could rank the different behaviors/properties of the AIA affected their trust in it. In this way, the critical implicit and explicit assurances will be identified. If the explicit assurance is near the top of the list of influencing assurances, then it is working; if not a re-design may need to occur. 
