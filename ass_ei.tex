\emph{Explicit and Implicit Assurances:}
This work has only considered \emph{designed algorithmic assurances}. However, users will always form some kind of trust relationship to an AIA, even if deliberately designed assurances are not available. In the absence of designed assurances, user trust is informed by \emph{implicit} undesigned assurances. These can be thought of as artifacts or side-effects of other design decisions not meant to directly influence user trust.

Why is it important to consider implicit assurances? There is always a danger that users attend to the `wrong' assurances, i.e. AIA features that are not meant to be interpreted as assurances but are nevertheless easily perceived as such (possibly more so than intended explicit assurances). For example, a designer may create a planning-predictability assurance for an autonomous wheeled mobile robot, which could be rendered ineffective by an implicit assurance given by the appearance of that robot, e.g. the user may trust it less if the robot has a flat tire or has a large tool attached to its front end which makes it `look unsafe'. 

It remains an open question as to how designers can identify and mitigate the impact of implicit assurances, especially so that they do not confound the intended effects of designed assurances. 
User studies will undoubtedly be helpful in obtaining feedback about which AIA characteristics most affect user trust, e.g. if explicit assurances are being picked up, and if there are implicit assurances that overwhelm explicitly designed assurances. With such feedback, designers would have a realistic idea about whether their explicitly designed assurances are having the desired effect on user TRBs. 
However, the design and analysis of this issue remains open for further study, and is likely to have many application-specific dependencies (though, in the spirit of this paper, cross-domain comparisons would also likely prove valuable). 
