\subsection{Trust-Related Behaviors} \label{sec:trbs}
Researchers of all disciplines widely accept that trust ultimately leads to some kind of meaningful behavior or action which reflects the level of trust; this idea was highlighted by \citet{Lewis1985-pr}.  \citet{McKnight2001-fa} call these `trust-related behaviors' (TRBs), which is the term that will be used in this survey. In the case of a human-AIA relationship per Figs. \ref{fig:SimpleTrust_one_way} and \ref{fig:RoadNet}, TRBs could include the kinds of tasks the human user assigns to the UGV, such as accepting and following through on its plan, or directing that a new plan be made, or switching off autonomous capabilities altogether to teleoperate the vehicle. 

\subsubsection{Calibration of Trust-Related Behaviors}
    Trust is not a univariate quantity that can be objectively measured. Rather, it is a multidimensional phenomenon whose `relative magnitudes and directions' must be observed through changes in TRBs, or qualitative self-reports reported in surveys \cite{Muir1996-gt}. It comes as no surprise that TRBs are the more objective measure due to the fact that people are not always consistent in their ratings, and may sincerely feel different levels of trust while performing similar TRBs. \citet{Parasuraman1997-co} were interested in understanding the use of automation by humans, and defined terms to describe that use. Here it is proposed that, by extension, those terms also apply to the behaviors of humans towards more advanced AIAs. Within this scope the definitions are as follows: \textit{Misuse:} over-reliance on an AIA (which could manifest itself in a user's unrealistically optimistic expectations of performance); \textit{Disuse:} under-utilization of an AIA (e.g. a user turning off the AIA, or failing to use all of its capabilities); \textit{Abuse:} Inappropriate application of an AIA (where \emph{application} in this case means the choice to deploy an AIA in a certain context). %, e.g. using a quad-copter underwater).
%    
%%    \edit{Trim/compress this part? }
%
%     \begin{description}
%         \item [Misuse:] The over-reliance on an AIA (which could manifest itself in a user's unrealistically optimistic expectations of AIA performance in a given situation)
%         \item [Disuse:] The under-utilization of and AIA (which could be manifest in a user turning off the AIA, or failing to use all of its capabilities)
%         \item [Abuse:] Inappropriate application of automation (where \emph{application} in this case means the choice to deploy an AIA in a certain context, e.g. using a quad-copter underwater).
%     \end{description}
%
%Recall the diagram in Fig.~\ref{fig:SimpleTrust_one_way}; the AIA has influence on the user's TRBs by way of assurances. 
Following Fig.~\ref{fig:SimpleTrust_one_way}, we propose that an AIA's assurances should be designed to steer the user away from misuse, disuse, or abuse of the AIA, i.e. towards otherwise appropriate TRBs. %Considering the space of all TRBs towards an AIA, this space would include misuse, disuse, abuse, and appropriate use (i.e. all TRBs not in misuse, disuse, or abuse). 
%To ensure that humans use AIAs appropriately, 
%It is thus critical that the user's TRBs be calibrated to elicit behaviors that are within the set of appropriate TRBs. 
This can only be done by properly `calibrating' assurances to suitably influence user trust. This is a point that, to some extent, has been informally mentioned in \cite{Muir1994-ow,Lillard2016-yg,Lee2004-pv,Hutchins2015-if}. 
%
Note that other researchers who propose `calibration' (or other similar concepts) often suggest calibrating \emph{trust} as opposed to TRBs. \citet{Dzindolet2003-ts} found that providing system performance feedback tended to increase user's \textit{self-reported trust}, even though user's resulting TRBs did not reflect self-reported trust levels. This shows the danger of calibrating `trust', as opposed to calibrating the TRBs. TRB calibration focuses on concrete and measurable behaviors that are universally applicable. In contrast, trust calibration involves influencing a quantity that is directly immeasurable, and that, when measured indirectly, is subject to individual human differences and biases. %%From this view, the findings of \citeauthor{Dzindolet2003-ts} are not surprising.

%%It is desirable for AIAs to be designed in order to encourage appropriate TRBs, as opposed to the alternative of purposefully misleading users to misuse, disuse, or abuse. One may even go so far as to argue that many of today's AIAs that ignore (or whose designers ignored) TRBs and assurances can be `unwittingly malicious', since they do not actively attempt to guide user's TRBs to lay within the space of appropriate TRBs.
