\section{Discussion}\label{sec:discussion} 
    After having investigated some of the literature there are several thoughts about assurances that can be made more concrete. Below we revisit the classification of assurances.
    \input{ass_conclusions.tex}

\section{Conclusions}\label{sec:conclusions}
\nisarcomm{I will deliberately hold off from commenting here in too much detail at this juncture, to give you the opportunity to make revisions here until after the other edits above are made... But I will caution that an important thing to state here (especially during your presentation) is what was actually learned, i.e. what are the major points that you came away with after this survey that you weren't aware of before? (recall Dale's question to Matt at end of his MS talk, i.e. what are the actual conclusions? Note that conclusions can also include pointers/statements of open questions and opportunities, e.g. 'An important conclusion is that blah blah blah is still an open problem, even though much work in specific cases of blah blah has been proposed...')}

    Now, more than ever, there is a great need for humans to be able to trust the AIAs that we are creating. Assurances are the method by which AIAs can encourage humans to trust them appropriately, and to then use them appropriately. We have presented here a definition, case for, and survey of assurances in the context of human-AIA trust relationships. These assurances have been classified according to different properties.
    
    The survey was performed from a standpoint of designing an unmanned ground vehicle that is working in concert with a human supervisor. However, the theoretical framework, and classification of assurances is meant to be general in order to apply to a broad range of AIAs.

    We propose that, when possible, TRBs should be calibrated instead of trust. This is due to the nature of subjective surveys and human psychology, which is that a human might rate their trust higher, but act no differently (as discussed in \cite{Dzindolet2003-ts}). 

    Generally opportunities for future research include performing experiments to test methods from \hyperref{Quadrant III.}{sec:q3} and identifying their effects. Furthermore, the fields of Validation and Verification, Representation Learning, Active Learning, Safety, Empirical Performance Prediction, and Model checking seem to be ripe for use in explicit assurances.

    \input{distrust.tex}

\newpage

