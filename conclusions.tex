\section{Conclusions}\label{sec:conclusions}
    Now, more than ever, there is a great need for humans to be able to trust the AIAs that we are creating. Assurances are the method by which AIAs can encourage humans to trust them appropriately, and to then use them appropriately. We have presented here a definition, case for, and survey of assurances in the context of human-AIA trust relationships. As a result, important considerations for designing assurances have been laid out and discussed.
    
    The survey was performed, to some extent, from a standpoint of designing an unmanned ground vehicle that is working in concert with a human supervisor. However, the theoretical framework, and classification of assurances is meant to be general in order to apply to a broad range of AIAs.

    There is a fairly large body of research that is focused, in some way, on influencing trust in human-AIA relationships. However, there is a larger portion of research that deals with techniques that would be useful in designing assurances, but that has not directly or knowingly considered affecting human-AIA trust through assurances as a formal design goal. Research from these areas (such as V\&V, active learning, and safety) should provide a rich collection of methods to be studied and formally applied to human-AIA trust relationships.

    While the basic definition of assurances (i.e. feedback to user trust, in the human-AIA trust cycle) is simple from a theoretical standpoint, the exercise of gathering related literature helped to illuminate some important considerations and details regarding the design of assurances. The components of Figure \ref{fig:refined_assurances} help to guide the design of assurances for human-AIA trust relationships.\nisarcomm{Recap the major components, and mention that this synthesis is part of the contribution of your survey.}

    Generally, we found that designers must consider how the affect of assurances will be measured, how to plan and calculate assurances, what mediums and methods to use, what limitations the AIA has on its ability to express an assurance, and different limitations of human users that need to be considered. Some areas for further research have been noted.

    A sobering reminder is that there is not a single assurance that will perform the best in all situations. Generally, having humans more involved -- as in visualization, or human-involved learning -- helps make the representations/functionality more `human-like' and thus more trustworthy. It is almost certain that given time highly specialized assurances can be designed for many situations. Even so we warn that, for the research and design of assurances to be sustainable in the current environment of fast-paced development of new technology, it is important to consider approaches that are as general as possible in order to be more easily used with newly developed methods for implementing AIA capabilities.

    The treatment of assurances in this survey are based, in part, on a model of trust. For completeness it is important to mention distrust. As reviewed and discussed by \citet{Lewicki1998-ox}, and formalized in \cite{McKnight2001-hm,McKnight2001-gz}. Low trust is not the same as distrust, neither is low distrust the same as trust. \citet{McKnight2001-gz} suggest that ``the emotional intensity of distrust distinguishes it from trust'', and they explain that distrust comes from emotions like: wariness, caution, and fear. Whereas, trust stems from emotions like: hope, safety, and confidence. Trust and distrust are orthogonal elements that define a person's TRB towards a trustee. 

    In this survey distrust was not considered, however it must be made clear that any \emph{complete} treatment of trust relationships, and for our purposes, designed assurances, must consider the dimensions of distrust as well as those of trust. For now, this investigation is left as an avenue for future research.

    We have identified many opportunities for further research in how AIAs can influence human trust through assurances. The framework found herein will help other researchers to see the field from a larger perspective, to classify the type of research they are performing, and help them to consider the greater implications of their work.

\nisarcomm{It is hard to pick out the actual `conclusions' of your survey from this section, i.e. what was actually learned or what should be the key takeaways -- you are summarizing what you did, but you are not clearly calling out key contributions or novel ideas/synthesis. I think these should be a bit more than just `we discussed important considerations': say/summarize what *are* the important considerations?

Also, like in the prelim oral exam: YOU FAILED TO SUMMARIZE THE MOTIVATION AND ARGUMENT ABOUT WHO THIS PAPER WAS AIMED AT AND WHY IT IS IMPORTANT FOR THE AUDIENCE TO READ THIS (recall that Eric said: the most important thing you said was at the very end! AFTER THE TALK WAS DONE!!) -- in other words, whose needle is this paper supposed to move, and why is the organization of the paper appropriate for that audience (esp the trust model survey and the synthesis at the end). Going back through Sections 1-3 to reiterate and connect the ideas from Section 5 to the key points along this line would help strengthen the claims to novelty/synthesis here. In other words, why is it important that CS people know about trust? Why should human factors people know about explainable ML techniques? etc. BE THOROUGH AND DELIBERATIVE ON THIS POINT -- what should people in those camps take away from this paper?}

\newpage

