The issues of user trust in AIAs, and appropriate deployment/use of AIAs have become very prominent.  Assurances are the method by which AIAs can influence humans to trust and (more importantly) \emph{use} them appropriately. We have presented here a definition, case for, and survey of algorithmic assurances in the context of human-AIA trust relationships. A formal treatment is necessary because the ecosystem of AIAs evolving to become more advanced than ever; consequently, previous informal approaches to designing assurances will not be sufficient.

This survey was performed, to some extent, from a standpoint of designing unmanned vehicle systems that must work in concert with a human supervisor. However, the theoretical framework and classification of assurances is meant to be general, in order to apply to a broad range of AIAs. One of the main motivations of this survey was the insight that there is an extremely large community of researchers working on human-AIA assurances (many unknowingly). It is important for the community to recognize this, so that researchers can organize their efforts and begin to methodically answer related open questions in this important area.

It is surprising that assurances have historically been practically ignored, and are the least understood component of human-AIA trust relationships. There have been many researchers who have recognized the concept of assurances, but no detailed definition has been given until now.

There are three main contributions from this work: 1) we have drawn from multiple bodies of research in order to fill in the missing details for the human-AIA trust cycle (Fig.~\ref{fig:SimpleTrust_one_way}) and to formally define assurances within this cycle; 2) we present a classification of assurances in Sec.~\ref{sec:assurances}; 3) we identify an `assurance integration continuum' shown in Fig.~\ref{fig:assurance_continuum}. On that continuum seven different classes of algorithms were identified. Practitioners can use these classes to select and design assurances for AIAs. In whole, given the material provided herein, those who design assurances should have the tools required to approach design from a solid theoretical foundation.

It is a sobering reminder that there is not a single assurance that will perform the best in all situations. It is almost certain that (given enough time) highly specialized assurances can be designed for many situations. Even so, we warn that, for the research and design of assurances to be sustainable in the current environment of fast-paced development of new technology, it is important to consider approaches that are as general as possible, in order to be more easily used with newly developed methods for implementing the various AIA capabilities.

We have identified many future opportunities for research on AIA assurance design and their influence on human trust, and hope researchers will begin looking outside of their own disciplines to discover, design and formally test new tools and ideas for assurance design and implementation. The framework presented here should unify research efforts by providing a common taxonomy. We believe it will help researchers see the field from a larger perspective, classify the type of research they are performing, and consider the greater implications of their work. The field of algorithmic assurances has an abundance of avenues for new research, and encourage researchers to pursue them.
