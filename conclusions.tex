\section{Conclusions}\label{sec:conclusions}
    Now, more than ever, there is a great need for humans to be able to trust the AIAs that we are creating. Assurances are the method by which AIAs can encourage humans to trust them appropriately, and to then use them appropriately. We have presented here a definition, case for, and survey of assurances in the context of human-AIA trust relationships. As a result, important considerations for designing assurances have been laid out and discussed.
    
    The survey was performed, to some extent, from a standpoint of designing an unmanned ground vehicle that is working in concert with a human supervisor. However, the theoretical framework, and classification of assurances is meant to be general in order to apply to a broad range of AIAs.

    There is a fairly large body of research that is focused, in some way, on influencing trust in human-AIA relationships. However, there is a larger portion of research that deals with techniques that would be useful in designing assurances, but that has not directly or consciously considered affecting human-AIA trust through assurances as a formal design goal. Research from these areas (such as V\&V, active learning, and safety) should provide a rich collection of methods to be studied and formally applied to human-AIA trust relationships.

    While the basic definition of assurances (i.e. feedback to user trust, in the human-AIA trust cycle) is simple from a theoretical standpoint, the exercise of gathering related literature helped to illuminate some important considerations and details regarding the design of assurances. The components of Figure \ref{fig:refined_assurances} help to guide the design of assurances for human-AIA trust relationships.

    Generally, we found that designers must consider how the affect of assurances will be measured, how to plan and calculate assurances, what mediums and methods to use, what limitations the AIA has on its ability to express an assurance, and different limitations of human users that need to be considered. Some areas for further research have been noted.

    \input{distrust.tex}

\newpage

